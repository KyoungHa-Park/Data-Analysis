{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [x] 데이터 불러오기(MySQL)\n",
    "+ [x] tokenizer(KoNLPy)\n",
    "+ [x] EDA\n",
    "+ [ ] Modeling/결과비교\n",
    "  + [ ] Topic(sickit-learn)\n",
    "  + [ ] LAD\n",
    "  + [ ] RNN\n",
    "  + [ ] 1D-CNN\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "path = 'C:/windows/Fonts/malgun.ttf'                           # 폰트:맑은고딕\n",
    "font_name = fm.FontProperties(fname=path, size=24).get_name()  \n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt(\"C:/Program Files/Java/jdk-12.0.1/bin/server/jvm.dll\")\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '201103_train_data_LIVECOMM.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# 2.자료 추출\n",
    "#####\n",
    "\n",
    "# DB연결\n",
    "conn = pymysql.connect(host = '10.223.7.4', user ='MAEIL_CS', password = \"Maeil01!@\", database='MAEIL_CS')\n",
    "\n",
    "# cursor 설정\n",
    "cursor = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "#자료 불러오기 : 전날 부정리뷰 겟수\n",
    "\n",
    "sql= '''select (SELECT CODE_NM FROM JT_CODE B WHERE A.COMPANY_CODE = B.CODE AND B.CODE_GRP_ID = 'DEALER_ID') as 수집체널 \n",
    "        , GROUP_CONCAT( distinct (SELECT concat(  '(', code, ') ' , code_nm) FROM JT_CODE B WHERE A.PRODUCT_CODE = B.CODE AND B.CODE_GRP_ID = 'PRODUCT') SEPARATOR ', ') as \"(code)구매제품\"\n",
    "        , A.WRITER as \"작성자ID\" , A.CONTENTS as 내용 , A.WRITE_DT as 작성일자 , A.GRADE as \"평점(5점 만점)\", PRODUCT_NO as \"상품번호(네이버)\"\n",
    "        FROM MAEIL_REVIEW A\n",
    "        where A.GRADE in (1,2)\n",
    "        and PRODUCT_CODE not like 'G_%'\n",
    "        group by A.COMPANY_CODE, A.WRITER, A.CONTENTS, A.WRITE_DT, A.GRADE, A.PRODUCT_NO\n",
    "        order by A.COMPANY_CODE, A.GRADE desc\n",
    "        '''\n",
    "\n",
    "cursor.execute(sql)\n",
    "result1 = cursor.fetchall()\n",
    "result1 = pd.DataFrame(result1)\n",
    "\n",
    "\n",
    "sql= '''select (SELECT CODE_NM FROM JT_CODE B WHERE A.COMPANY_CODE = B.CODE AND B.CODE_GRP_ID = 'DEALER_ID') as 수집체널 \n",
    "        , GROUP_CONCAT( distinct (SELECT concat(  '(', code, ') ' , code_nm) FROM JT_CODE B WHERE A.PRODUCT_CODE = B.CODE AND B.CODE_GRP_ID = 'PRODUCT') SEPARATOR ', ') as \"(code)구매제품\"\n",
    "        , A.WRITER as \"작성자ID\" , A.CONTENTS as 내용 , A.WRITE_DT as 작성일자 , A.GRADE as \"평점(5점 만점)\", PRODUCT_NO as \"상품번호(네이버)\"\n",
    "        FROM MAEIL_REVIEW A\n",
    "        where A.GRADE in (4,5)\n",
    "        and WRITE_DT between DATE_SUB(CURDATE(), INTERVAL 1 DAY) and (CURDATE())\n",
    "        and PRODUCT_CODE not like 'G_%'\n",
    "        group by A.COMPANY_CODE, A.WRITER, A.CONTENTS, A.WRITE_DT, A.GRADE, A.PRODUCT_NO\n",
    "        order by A.COMPANY_CODE, A.GRADE desc\n",
    "        '''\n",
    "\n",
    "cursor.execute(sql)\n",
    "result2 = cursor.fetchall()\n",
    "result2 = pd.DataFrame(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0 = pd.concat([result1, result2])\n",
    "result0 = result0[['(code)구매제품', '내용', '평점(5점 만점)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0['평점(5점 만점)'] = result0['평점(5점 만점)'].astype(int)\n",
    "result0['평점(5점 만점)'] = np.select([result0['평점(5점 만점)'] >= 3], [1], default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(code)구매제품</th>\n",
       "      <th>내용</th>\n",
       "      <th>평점(5점 만점)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>(106111) 셀렉스 코어프로틴 [ 스틱 ] [ 19g x 10 ]</td>\n",
       "      <td>이런 이벤트 좋아요 동네방네 소문내고 있어요ㅋ 유통기한도 길어서 좋네요</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>(106526) 밀크세라마이드 체험키트 [ 7포 ] [ NEW ]</td>\n",
       "      <td>약간 시큼한 분유맛 맛있어요. 분유 훔쳐먹던 생각도나고ㅎㅎ 맛있는간식이 되겠어요</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>(106012) 셀렉스 슬림 25 [ 말차 ] [ 36g x 10 ]</td>\n",
       "      <td>맛있는 녹차라떼 맛이에요 세일해서 득템하네요 세일자주해주세요 맛있어요</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>(106011) 셀렉스 슬림 25 [ 그레인 ] [ 36g x 10 ]</td>\n",
       "      <td>맛있네요 다이어트아니어도 단백질보충용으로도 휼륭해요 엄마도 좋아하세요 맛있다고</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>(106018) 셀렉스 코어프로틴플러스 [ 304g ]</td>\n",
       "      <td>좋 습 니 다\\n영양가도 많고  \\n유효기간도1년 이네요\\n닭가슴살과 같이 먹으면 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   (code)구매제품  \\\n",
       "1962   (106111) 셀렉스 코어프로틴 [ 스틱 ] [ 19g x 10 ]   \n",
       "1963     (106526) 밀크세라마이드 체험키트 [ 7포 ] [ NEW ]   \n",
       "1964   (106012) 셀렉스 슬림 25 [ 말차 ] [ 36g x 10 ]   \n",
       "1965  (106011) 셀렉스 슬림 25 [ 그레인 ] [ 36g x 10 ]   \n",
       "1966           (106018) 셀렉스 코어프로틴플러스 [ 304g ]   \n",
       "\n",
       "                                                     내용  평점(5점 만점)  \n",
       "1962            이런 이벤트 좋아요 동네방네 소문내고 있어요ㅋ 유통기한도 길어서 좋네요          5  \n",
       "1963       약간 시큼한 분유맛 맛있어요. 분유 훔쳐먹던 생각도나고ㅎㅎ 맛있는간식이 되겠어요          5  \n",
       "1964             맛있는 녹차라떼 맛이에요 세일해서 득템하네요 세일자주해주세요 맛있어요          5  \n",
       "1965        맛있네요 다이어트아니어도 단백질보충용으로도 휼륭해요 엄마도 좋아하세요 맛있다고          5  \n",
       "1966  좋 습 니 다\\n영양가도 많고  \\n유효기간도1년 이네요\\n닭가슴살과 같이 먹으면 ...          4  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(result0.groupby(['평점(5점 만점)']).count().index, result0.groupby(['평점(5점 만점)']).count()['내용'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  tokenizer(KoNLPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(code)구매제품</th>\n",
       "      <th>내용</th>\n",
       "      <th>평점(5점 만점)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>(106011) 셀렉스 슬림 25 [ 그레인 ] [ 36g x 10 ]</td>\n",
       "      <td>맛있네요 다이어트아니어도 단백질보충용으로도 휼륭해요 엄마도 좋아하세요 맛있다고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>(106018) 셀렉스 코어프로틴플러스 [ 304g ]</td>\n",
       "      <td>좋 습 니 다\\n영양가도 많고  \\n유효기간도1년 이네요\\n닭가슴살과 같이 먹으면 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   (code)구매제품  \\\n",
       "1965  (106011) 셀렉스 슬림 25 [ 그레인 ] [ 36g x 10 ]   \n",
       "1966           (106018) 셀렉스 코어프로틴플러스 [ 304g ]   \n",
       "\n",
       "                                                     내용  평점(5점 만점)  \n",
       "1965        맛있네요 다이어트아니어도 단백질보충용으로도 휼륭해요 엄마도 좋아하세요 맛있다고          1  \n",
       "1966  좋 습 니 다\\n영양가도 많고  \\n유효기간도1년 이네요\\n닭가슴살과 같이 먹으면 ...          1  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#한글 토큰화\n",
    "#####\n",
    "\n",
    "# 1차 가공 : koNLpy to token\n",
    "def tokenize(doc):\n",
    "    result = [t for t in okt.pos(doc, norm=True, stem=True)] # ex '더빙/Norm', '나다/Verb'\n",
    "    return result \n",
    "\n",
    "token_data1 = [tokenize(row) for row in result0['내용']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('맛', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('생각', 'Noun'),\n",
       " ('보다', 'Josa'),\n",
       " ('물', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('타다', 'Verb'),\n",
       " ('듯', 'Noun'),\n",
       " ('해', 'Noun'),\n",
       " ('요', 'Josa'),\n",
       " ('.', 'Punctuation'),\n",
       " ('\\r\\n', 'Foreign'),\n",
       " ('배송', 'Noun'),\n",
       " ('괜찮다', 'Adjective'),\n",
       " ('!', 'Punctuation')]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_data1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data2 = []\n",
    "for i in range(0, len(token_data1)):\n",
    "    r = []\n",
    "    for word in token_data1[i]:\n",
    "        if not word[1] in [\"Josa\", \"Punctuation\", \"Foreign\", \"Suffix\", \"Eomi\"]:\n",
    "            r.append(word[0])\n",
    "    token_data2.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('가성', 'Noun'), ('비', 'Noun'), ('떨어지다', 'Verb'), ('200', 'Number'), ('mm', 'Alpha'), ('48', 'Number'), ('팩', 'Noun'), ('더', 'Noun'), ('쓸모', 'Noun'), ('가', 'Josa'), ('있다', 'Adjective'), ('\\r\\n', 'Foreign'), ('배송', 'Noun'), ('별로', 'Noun'), ('예요', 'Josa'), ('!', 'Punctuation')]\n",
      "\n",
      "['가성', '비', '떨어지다', '200', 'mm', '48', '팩', '더', '쓸모', '있다', '배송', '별로']\n"
     ]
    }
   ],
   "source": [
    "i =51 \n",
    "print(token_data1[i])\n",
    "print('')\n",
    "print(token_data2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '때', '더', '올', '지', '께',\n",
    "             '안','다','요','것','로','무','머','하고','늘','했어요','나','고', '해', '에서', '입니다','을','저','매', '일','오', '씩'\n",
    "             '아주', '인', '랑']\n",
    "\n",
    "X_train = []\n",
    "for sentence in token_data2:\n",
    "    temp_X = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_trim2.str.startswith('/Josa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling 1 :  Topic(sickit-learn)\n",
    "\n",
    "+ mulit-model에 대한 검증(비교)을 할 것인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    return(topic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 및 단어집 만들기\n",
    "dictionary = corpora.Dictionary(X_train)\n",
    "corpus = [dictionary.doc2bow(text) for text in X_train]\n",
    "\n",
    "# 토픽 겟수 설정 : 20개\n",
    "NUM_TOPICS = 20 \n",
    "\n",
    "# LAD 모델링\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 현황 확인\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.DataFrame()\n",
    "df_item['가장 비중이 높은 토픽'] = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "df_item['Category'] = ['재구매','맛','맛','배송','유통기한','맛','맛','맛','배송','맛','맛','맛','맛','재구매','맛','맛','맛','재구매','akt','배송']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "temp_file = datapath(\"model\")\n",
    "ldamodel.save(temp_file)\n",
    "\n",
    "# model load\n",
    "# ldamodel = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame 만들기\n",
    "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
    "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
    "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
    "\n",
    "topictable['(code)구매제품'] = list(result0['(code)구매제품'])\n",
    "topictable['내용'] = list(result0['내용'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topictable2 = pd.merge(topictable, df_item, on ='가장 비중이 높은 토픽')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topictable2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(topictable.groupby(['가장 비중이 높은 토픽']).count().index, topictable.groupby(['가장 비중이 높은 토픽']).count()['내용'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(topictable2.groupby(['Category']).count().index, topictable2.groupby(['Category']).count()['내용'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 자료 저장 v2\n",
    "writer = pd.ExcelWriter('./210419_NLP_LDA.xlsx')\n",
    "topictable.to_excel(writer, 'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling 2 :  RNN\n",
    "+ categorical transf\n",
    "+ test/train split\n",
    "+ tokenizer\n",
    "+ pedding\n",
    "+ model\n",
    "+ optimizer/loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(code)구매제품</th>\n",
       "      <th>내용</th>\n",
       "      <th>평점(5점 만점)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]</td>\n",
       "      <td>아이들 먹기는 싱겁고 걍 어른용이 어울리네요\\r\\n배송 아주 좋아요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]</td>\n",
       "      <td>더 비싸게 파는데 톡딜의 의미가 없죠..\\r\\n배송 괜찮아요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]</td>\n",
       "      <td>맛이 생각보다 물에 탄 듯 해요.\\r\\n배송 괜찮아요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(106141) 멸균 상하목장 유기농 우유 [ 125ML ] [ NEW 콤비블록 ]</td>\n",
       "      <td>이렇게 까지 작을 줄 몰랐어요ㅋㅋㅋㅋ 아기들 먹는 우유인것 같아요! 맛은 분유맛 나...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(106141) 멸균 상하목장 유기농 우유 [ 125ML ] [ NEW 콤비블록 ]</td>\n",
       "      <td>일반 멸균 용량이 아니라 미니 사이즈네요 용량 확인안한 구매실수....\\r\\n배송 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       (code)구매제품  \\\n",
       "0            (105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]   \n",
       "1            (105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]   \n",
       "2            (105645) 멸균 아몬드브리즈 [ 프로틴 ] [ 190ml ]   \n",
       "3  (106141) 멸균 상하목장 유기농 우유 [ 125ML ] [ NEW 콤비블록 ]   \n",
       "4  (106141) 멸균 상하목장 유기농 우유 [ 125ML ] [ NEW 콤비블록 ]   \n",
       "\n",
       "                                                  내용  평점(5점 만점)  \n",
       "0             아이들 먹기는 싱겁고 걍 어른용이 어울리네요\\r\\n배송 아주 좋아요!          0  \n",
       "1                 더 비싸게 파는데 톡딜의 의미가 없죠..\\r\\n배송 괜찮아요!          0  \n",
       "2                     맛이 생각보다 물에 탄 듯 해요.\\r\\n배송 괜찮아요!          0  \n",
       "3  이렇게 까지 작을 줄 몰랐어요ㅋㅋㅋㅋ 아기들 먹는 우유인것 같아요! 맛은 분유맛 나...          0  \n",
       "4  일반 멸균 용량이 아니라 미니 사이즈네요 용량 확인안한 구매실수....\\r\\n배송 ...          0  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical transf\n",
    "topictable2 = pd.DataFrame()\n",
    "topictable2[\"lable\"] = result0[\"평점(5점 만점)\"].astype('category').cat.codes\n",
    "topictable2['tokenized'] = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lable</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[아이, 먹기, 싱겁다, 어른, 용이, 어울리다, 배송, 아주, 좋다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[비싸다, 팔다, 톡딜, 의미, 없다, 배송, 괜찮다]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lable                                tokenized\n",
       "0      0  [아이, 먹기, 싱겁다, 어른, 용이, 어울리다, 배송, 아주, 좋다]\n",
       "1      0           [비싸다, 팔다, 톡딜, 의미, 없다, 배송, 괜찮다]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topictable2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(topictable2, test_size = 0.25, random_state = 42)\n",
    "\n",
    "X_train = train_data['tokenized'].values\n",
    "y_train = train_data['lable'].values\n",
    "X_test= test_data['tokenized'].values\n",
    "y_test = test_data['lable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer(정수 인코딩)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 3801\n",
      "등장 빈도가 1번 이하인 희귀 단어의 수: 1792\n",
      "단어 집합에서 희귀 단어의 비율: 47.14548802946593\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.5735257526747946\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "vocab_size = total_cnt - rare_cnt + 2\n",
    "# print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[598, 29, 2, 1, 3]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pedding\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 93.81003201707577\n"
     ]
    }
   ],
   "source": [
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,   27, 1204,  241,   93,   10,    2])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#레이어 구성\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, max_len))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# hyper parameter 설정\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# loss 설정\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 30)          60330     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               81408     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 141,867\n",
      "Trainable params: 141,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6445 - acc: 0.6561\n",
      "Epoch 00001: val_acc improved from -inf to 0.78330, saving model to best_model.h5\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.6445 - acc: 0.6561 - val_loss: 0.5348 - val_acc: 0.7833\n",
      "Epoch 2/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8225\n",
      "Epoch 00002: val_acc improved from 0.78330 to 0.83126, saving model to best_model.h5\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.4353 - acc: 0.8243 - val_loss: 0.3885 - val_acc: 0.8313\n",
      "Epoch 3/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.8986\n",
      "Epoch 00003: val_acc improved from 0.83126 to 0.86679, saving model to best_model.h5\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2953 - acc: 0.8986 - val_loss: 0.3425 - val_acc: 0.8668\n",
      "Epoch 4/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9108\n",
      "Epoch 00004: val_acc improved from 0.86679 to 0.88277, saving model to best_model.h5\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2507 - acc: 0.9110 - val_loss: 0.3121 - val_acc: 0.8828\n",
      "Epoch 5/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9207\n",
      "Epoch 00005: val_acc improved from 0.88277 to 0.89520, saving model to best_model.h5\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2104 - acc: 0.9199 - val_loss: 0.2777 - val_acc: 0.8952\n",
      "Epoch 6/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9320\n",
      "Epoch 00006: val_acc did not improve from 0.89520\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.1824 - acc: 0.9310 - val_loss: 0.2749 - val_acc: 0.8863\n",
      "Epoch 7/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9405\n",
      "Epoch 00007: val_acc did not improve from 0.89520\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.1671 - acc: 0.9399 - val_loss: 0.3080 - val_acc: 0.8881\n",
      "Epoch 8/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9432\n",
      "Epoch 00008: val_acc improved from 0.89520 to 0.89698, saving model to best_model.h5\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.1593 - acc: 0.9426 - val_loss: 0.2872 - val_acc: 0.8970\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1396 - acc: 0.9462\n",
      "Epoch 00009: val_acc did not improve from 0.89698\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.1396 - acc: 0.9462 - val_loss: 0.3344 - val_acc: 0.8774\n",
      "Epoch 10/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9532\n",
      "Epoch 00010: val_acc did not improve from 0.89698\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.1290 - acc: 0.9524 - val_loss: 0.3040 - val_acc: 0.8934\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3396 - acc: 0.8902\n",
      "\n",
      " 테스트 정확도: 0.8902\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-308-518757d264a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. model evalustion : v1\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['acc'])\n",
    "plt.plot(epochs, history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_accuracy', 'test_accuracy'], loc='lower right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train_loss', 'test_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#레이어 구성\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(30,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#학습 프로세스 설정\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# hyper parameter 설정\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 64)                1984      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,593\n",
      "Trainable params: 14,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 9.5812 - acc: 0.5306 \n",
      "Epoch 00001: val_acc improved from -inf to 0.46536, saving model to best_model.h5\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 8.9235 - acc: 0.5254 - val_loss: 6.4420 - val_acc: 0.4654\n",
      "Epoch 2/100\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 5.0573 - acc: 0.5631\n",
      "Epoch 00002: val_acc improved from 0.46536 to 0.55240, saving model to best_model.h5\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0345 - acc: 0.5649 - val_loss: 5.2222 - val_acc: 0.5524\n",
      "Epoch 3/100\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 3.4250 - acc: 0.5981\n",
      "Epoch 00003: val_acc did not improve from 0.55240\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.3107 - acc: 0.5961 - val_loss: 4.5079 - val_acc: 0.5311\n",
      "Epoch 4/100\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 2.7544 - acc: 0.6051\n",
      "Epoch 00004: val_acc improved from 0.55240 to 0.55417, saving model to best_model.h5\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6902 - acc: 0.6125 - val_loss: 3.9834 - val_acc: 0.5542\n",
      "Epoch 5/100\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 2.3494 - acc: 0.6271\n",
      "Epoch 00005: val_acc improved from 0.55417 to 0.57194, saving model to best_model.h5\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.4081 - acc: 0.6210 - val_loss: 3.1581 - val_acc: 0.5719\n",
      "Epoch 6/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 1.8172 - acc: 0.6303\n",
      "Epoch 00006: val_acc improved from 0.57194 to 0.58437, saving model to best_model.h5\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8458 - acc: 0.6272 - val_loss: 4.8882 - val_acc: 0.5844\n",
      "Epoch 7/100\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 1.3776 - acc: 0.6828\n",
      "Epoch 00007: val_acc improved from 0.58437 to 0.61456, saving model to best_model.h5\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5173 - acc: 0.6713 - val_loss: 3.4279 - val_acc: 0.6146\n",
      "Epoch 8/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 1.3612 - acc: 0.6586\n",
      "Epoch 00008: val_acc did not improve from 0.61456\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3393 - acc: 0.6641 - val_loss: 2.5877 - val_acc: 0.6039\n",
      "Epoch 9/100\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 1.1892 - acc: 0.6879\n",
      "Epoch 00009: val_acc did not improve from 0.61456\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1984 - acc: 0.6819 - val_loss: 2.8770 - val_acc: 0.5790\n",
      "Epoch 10/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.9979 - acc: 0.6938\n",
      "Epoch 00010: val_acc did not improve from 0.61456\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0293 - acc: 0.6877 - val_loss: 2.5948 - val_acc: 0.6128\n",
      "Epoch 11/100\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.9860 - acc: 0.6887\n",
      "Epoch 00011: val_acc did not improve from 0.61456\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9563 - acc: 0.6944 - val_loss: 2.6249 - val_acc: 0.5879\n",
      "Epoch 12/100\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.9319 - acc: 0.7080\n",
      "Epoch 00012: val_acc did not improve from 0.61456\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8998 - acc: 0.7095 - val_loss: 2.6533 - val_acc: 0.5613\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터로 학습\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(max_len,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "digits (InputLayer)             [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           1984        digits[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           650         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [()]                 0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [()]                 0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_1 (AddLoss)            ()                   0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [(1, 1)]             0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 64)]         0           dense_1[0][0]                    \n",
      "                                                                 tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_1 (TensorFlo [(None, 64)]         0           tf_op_layer_Sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_3 (TensorFlowO [()]                 0           tf_op_layer_Square_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_1 (TensorFlowO [()]                 0           tf_op_layer_Mean_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_metric_1 (AddMetric)        ()                   0           tf_op_layer_Sqrt_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 6,794\n",
      "Trainable params: 6,794\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 16596.5801 - std_of_activation: 102.3097WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 16462.6797 - std_of_activation: 101.7784 - val_loss: 11058.9766 - val_std_of_activation: 78.5574\n",
      "Epoch 2/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 7928.6924 - std_of_activation: 61.3633 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7778.4341 - std_of_activation: 60.6171 - val_loss: 5333.7363 - val_std_of_activation: 48.1500\n",
      "Epoch 3/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 3775.1057 - std_of_activation: 36.9262WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3615.8582 - std_of_activation: 35.9273 - val_loss: 2456.2634 - val_std_of_activation: 28.8409\n",
      "Epoch 4/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 1633.7117 - std_of_activation: 21.1125WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1599.6176 - std_of_activation: 20.7190 - val_loss: 1068.5292 - val_std_of_activation: 16.5828\n",
      "Epoch 5/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 870.7495 - std_of_activation: 14.8845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 646.0937 - std_of_activation: 11.4032 - val_loss: 411.2144 - val_std_of_activation: 8.8612\n",
      "Epoch 6/100\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 241.6571 - std_of_activation: 6.1321WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 234.7357 - std_of_activation: 5.9762 - val_loss: 143.0350 - val_std_of_activation: 4.5404\n",
      "Epoch 7/100\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 88.8065 - std_of_activation: 3.4551WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 77.8058 - std_of_activation: 3.1735 - val_loss: 48.8339 - val_std_of_activation: 2.4779\n",
      "Epoch 8/100\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 31.6985 - std_of_activation: 1.9934WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 28.9549 - std_of_activation: 1.9105 - val_loss: 23.1069 - val_std_of_activation: 1.6988\n",
      "Epoch 9/100\n",
      "25/38 [==================>...........] - ETA: 0s - loss: 13.8937 - std_of_activation: 1.1957WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 15.4818 - std_of_activation: 1.2377 - val_loss: 14.6015 - val_std_of_activation: 1.2709\n",
      "Epoch 10/100\n",
      "25/38 [==================>...........] - ETA: 0s - loss: 9.8617 - std_of_activation: 0.7802WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 10.5310 - std_of_activation: 0.8616 - val_loss: 10.5656 - val_std_of_activation: 1.0008\n",
      "Epoch 11/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 20.3402 - std_of_activation: 2.2031WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.3769 - std_of_activation: 0.6585 - val_loss: 8.6207 - val_std_of_activation: 0.8290\n",
      "Epoch 12/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 51.3987 - std_of_activation: 3.0408WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4842 - std_of_activation: 0.5187 - val_loss: 7.0939 - val_std_of_activation: 0.6857\n",
      "Epoch 13/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.6960 - std_of_activation: 0.0000e+00WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1468 - std_of_activation: 0.3805 - val_loss: 6.0335 - val_std_of_activation: 0.5792\n",
      "Epoch 14/100\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 2.9328 - std_of_activation: 0.2189    WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.2424 - std_of_activation: 0.2576 - val_loss: 5.2225 - val_std_of_activation: 0.4983\n",
      "Epoch 15/100\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 2.0570 - std_of_activation: 0.1547    WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.4515 - std_of_activation: 0.2021 - val_loss: 4.5313 - val_std_of_activation: 0.4168\n",
      "Epoch 16/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 1.8895 - std_of_activation: 0.1376    WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8748 - std_of_activation: 0.1340 - val_loss: 4.4336 - val_std_of_activation: 0.4147\n",
      "Epoch 17/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.6941 - std_of_activation: 0.0000e+00WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5987 - std_of_activation: 0.1057 - val_loss: 4.4369 - val_std_of_activation: 0.4147\n",
      "Epoch 18/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 9.0926 - std_of_activation: 1.0221WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.3997 - std_of_activation: 0.0770 - val_loss: 4.4407 - val_std_of_activation: 0.4147\n",
      "Epoch 19/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.6985 - std_of_activation: 0.0000e+00WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2482 - std_of_activation: 0.0710 - val_loss: 4.4372 - val_std_of_activation: 0.4147\n",
      "Epoch 20/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 1.1219 - std_of_activation: 0.0575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1167 - std_of_activation: 0.0560 - val_loss: 4.4377 - val_std_of_activation: 0.4147\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
