{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579bbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65b09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157d872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ac0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "    str1 = \"\"  \n",
    "    for ele in s:  \n",
    "        str1 += \" \" + ele.strip()\n",
    "    return str1\n",
    "\n",
    "def max_sum_sim(doc_embedding, candidate_embeddings, words, top_n, nr_candidates):\n",
    "    # 문서와 각 키워드들 간의 유사도\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    distances_candidates = cosine_similarity(candidate_embeddings, candidate_embeddings)\n",
    "\n",
    "    # 코사인 유사도에 기반하여 키워드들 중 상위 top_n개의 단어를 pick.\n",
    "    words_idx = list(distances.argsort()[0][-nr_candidates:])\n",
    "    words_vals = [candidates[index] for index in words_idx]\n",
    "    distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "    # 각 키워드들 중에서 가장 덜 유사한 키워드들간의 조합을 계산\n",
    "    min_sim = np.inf\n",
    "    candidate = None\n",
    "    for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "        sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n",
    "        if sim < min_sim:\n",
    "            candidate = combination\n",
    "            min_sim = sim\n",
    "\n",
    "    return [words_vals[idx] for idx in candidate]\n",
    "\n",
    "\n",
    "def mmr(doc_embedding, candidate_embeddings, words, top_n, diversity):\n",
    "\n",
    "    # 문서와 각 키워드들 간의 유사도가 적혀있는 리스트\n",
    "    word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n",
    "\n",
    "    # 각 키워드들 간의 유사도\n",
    "    word_similarity = cosine_similarity(candidate_embeddings)\n",
    "\n",
    "    # 문서와 가장 높은 유사도를 가진 키워드의 인덱스를 추출.\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # keywords_idx = [2]\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "\n",
    "    # 가장 높은 유사도를 가진 키워드의 인덱스를 제외한 문서의 인덱스들\n",
    "    # 만약, 2번 문서가 가장 유사도가 높았다면\n",
    "    # ==> candidates_idx = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10 ... 중략 ...]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    # 최고의 키워드는 이미 추출했으므로 top_n-1번만큼 아래를 반복.\n",
    "    # ex) top_n = 5라면, 아래의 loop는 4번 반복됨.\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # MMR을 계산\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # keywords & candidates를 업데이트\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51ca64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623a43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b6ef5116e8474c97f66b3d4cf4303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ab895/.gitattributes:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6debc61f4b1463cbd7a441dfaf6056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e101929de54f58b42739be39a3364a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f9e99ab895/README.md:   0%|          | 0.00/4.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185ccd43f38c4ebb87af4597e3641e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e99ab895/config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b141c70b3a4844aeae01bd3b2633cfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5049a7d366e54903ac04ffb407b5f181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a692c4ee254d138b0103915b73fafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf4954f6e3f41b88e690b7559265d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fd193bcd3448558dac7182d134437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891c7d78fffe4eed8be6093dc5d63da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc500b73c244558906d5d0033b05d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb875eac3da448e1ab66faac3e4ad48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)99ab895/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens') # OK / 10분?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bbbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7242ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b49df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "df = pd.read_excel('./20230327_review_data5_temp.xlsx', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd03ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleansing\n",
    "try:\n",
    "    doc = listToString(df.REVIEW.sample(frac = 1))\n",
    "except:\n",
    "    doc = listToString(df.리뷰상세내용.sample(frac = 1))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28150784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e39daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram 개수 : 15549\n",
      "trigram 10개만 출력 : ['가격 같아서' '가격 같아서 만족합니다' '가격 구매' '가격 구매 해서' '가격 구매 했어요' '가격 구입'\n",
      " '가격 구입 있어서' '가격 구입 했어요' '가격 내려가']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "tokenized_doc = okt.pos(doc)\n",
    "tokenized_nouns = ' '.join([word[0] for word in tokenized_doc if (word[1] == 'Noun') | (word[1] == 'Verb') | (word[1] == 'Adjective')])\n",
    "\n",
    "# 2음절 ~ 3음절\n",
    "n_gram_range = (2, 3)\n",
    "\n",
    "count = CountVectorizer(ngram_range=n_gram_range).fit([tokenized_nouns])\n",
    "candidates = count.get_feature_names_out()\n",
    "\n",
    "print('bi/trigram 개수 :',len(candidates))\n",
    "print('bi/trigram 10개만 출력 :',candidates[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a4a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61bee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서간 유사도\n",
    "doc_embedding = model.encode([doc])\n",
    "\n",
    "# 단어간 유사도 : 30분 초과시 pass\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9235a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdadc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 15\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "keywords3 = mmr(doc_embedding, candidate_embeddings, candidates, top_n=15, diversity=0.8)\n",
    "keywords2 =  max_sum_sim(doc_embedding, candidate_embeddings, candidates, top_n=15, nr_candidates=20)\n",
    "\n",
    "df_k = pd.DataFrame()\n",
    "df_k['BERT'] =  keywords\n",
    "df_k['BERT_MMS'] =  keywords2\n",
    "df_k['BERT_MMR'] =  keywords3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1548168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT</th>\n",
       "      <th>BERT_MMS</th>\n",
       "      <th>BERT_MMR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>깔끔한 포장</td>\n",
       "      <td>포장 넉넉한 유통</td>\n",
       "      <td>좋아합니다 맛있고 포장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>맛있어요 쿠키 먹어</td>\n",
       "      <td>꼼꼼하고 상품 터짐</td>\n",
       "      <td>우유 유통 기한</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>두유 맛있어요 먹겠습니다</td>\n",
       "      <td>건강한 쿠키</td>\n",
       "      <td>감자 불고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>넉넉한 깨끗한 물품</td>\n",
       "      <td>깔끔한 포장</td>\n",
       "      <td>마음 매일유업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>진쪼 좋아합니다 맛있고</td>\n",
       "      <td>맛있어요 쿠키 먹어</td>\n",
       "      <td>상자 자녀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>제품 건강한 단맛</td>\n",
       "      <td>두유 맛있어요 먹겠습니다</td>\n",
       "      <td>다른 유통업체</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>맛있어요 간편하게 먹을수있어요</td>\n",
       "      <td>넉넉한 깨끗한 물품</td>\n",
       "      <td>마트 인터넷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>빠르고 자잘한 포장재</td>\n",
       "      <td>진쪼 좋아합니다 맛있고</td>\n",
       "      <td>다음 토욜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>포장 꼼꼼하고 유통기간</td>\n",
       "      <td>제품 건강한 단맛</td>\n",
       "      <td>개는 깨져서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>맛있어요 요거트 만들어져요</td>\n",
       "      <td>빠르고 자잘한 포장재</td>\n",
       "      <td>폭풍 성장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>포장 꼼꼼하고 상품</td>\n",
       "      <td>포장 꼼꼼하고 유통기간</td>\n",
       "      <td>궁금했던 유기농 블루베리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>포장 깔끔하고 유통</td>\n",
       "      <td>맛있어요 요거트 만들어져요</td>\n",
       "      <td>불필요한 플라스틱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>쿠키 맛있습니다 자주</td>\n",
       "      <td>포장 깔끔하고 유통</td>\n",
       "      <td>칼슘 비타민</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>매일유업 최고 먹진</td>\n",
       "      <td>쿠키 맛있습니다 자주</td>\n",
       "      <td>토끼 털모자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>좋아합니다 맛있고 포장</td>\n",
       "      <td>매일유업 최고 먹진</td>\n",
       "      <td>열어주세용 이번 라이브</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BERT        BERT_MMS       BERT_MMR\n",
       "0             깔끔한 포장       포장 넉넉한 유통   좋아합니다 맛있고 포장\n",
       "1         맛있어요 쿠키 먹어      꼼꼼하고 상품 터짐       우유 유통 기한\n",
       "2      두유 맛있어요 먹겠습니다          건강한 쿠키         감자 불고기\n",
       "3         넉넉한 깨끗한 물품          깔끔한 포장        마음 매일유업\n",
       "4       진쪼 좋아합니다 맛있고      맛있어요 쿠키 먹어          상자 자녀\n",
       "5          제품 건강한 단맛   두유 맛있어요 먹겠습니다        다른 유통업체\n",
       "6   맛있어요 간편하게 먹을수있어요      넉넉한 깨끗한 물품         마트 인터넷\n",
       "7        빠르고 자잘한 포장재    진쪼 좋아합니다 맛있고          다음 토욜\n",
       "8       포장 꼼꼼하고 유통기간       제품 건강한 단맛         개는 깨져서\n",
       "9     맛있어요 요거트 만들어져요     빠르고 자잘한 포장재          폭풍 성장\n",
       "10        포장 꼼꼼하고 상품    포장 꼼꼼하고 유통기간  궁금했던 유기농 블루베리\n",
       "11        포장 깔끔하고 유통  맛있어요 요거트 만들어져요      불필요한 플라스틱\n",
       "12       쿠키 맛있습니다 자주      포장 깔끔하고 유통         칼슘 비타민\n",
       "13        매일유업 최고 먹진     쿠키 맛있습니다 자주         토끼 털모자\n",
       "14      좋아합니다 맛있고 포장      매일유업 최고 먹진   열어주세용 이번 라이브"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023b8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KeyBERT'] =0\n",
    "for t in keywords3:\n",
    "    temp = list(t.split())\n",
    "    text1, text2, text3 = temp[0],  temp[1],  temp[-1]\n",
    "    try:\n",
    "        df.loc[(df['REVIEW'].str.contains(str(text1))) & (df['REVIEW'].str.contains(str(text2))) & (df['REVIEW'].str.contains(str(text3))) , 'KeyBERT'] = 1\n",
    "    except:\n",
    "        df.loc[(df['리뷰상세내용'].str.contains(str(text1))) & (df['리뷰상세내용'].str.contains(str(text2))) & (df['리뷰상세내용'].str.contains(str(text3))) , 'KeyBERT'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc6b8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0231f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GROUP2</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>리뷰상세내용</th>\n",
       "      <th>구매자평점</th>\n",
       "      <th>포토/영상</th>\n",
       "      <th>등록자</th>\n",
       "      <th>리뷰등록일1</th>\n",
       "      <th>상품번호</th>\n",
       "      <th>상품명</th>\n",
       "      <th>product_nm</th>\n",
       "      <th>token</th>\n",
       "      <th>token_attribution2</th>\n",
       "      <th>lenght</th>\n",
       "      <th>KeyBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>38440</td>\n",
       "      <td>제품포장</td>\n",
       "      <td>포장</td>\n",
       "      <td>포장 잘 되있어요\\n간식용으로 구매해서 불필요한 플라스틱케이스 없어서 좋아요</td>\n",
       "      <td>5</td>\n",
       "      <td>https://phinf.pstatic.net/checkout.phinf/20230...</td>\n",
       "      <td>ssk9***</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>4697498993</td>\n",
       "      <td>페레로 로쉐 T3 3개입 16세트 (총 48개입) (쇼핑백 없는 구성)</td>\n",
       "      <td>페레로 [ 로쉐 ] [ t3 ]</td>\n",
       "      <td>포장 자다 되다 어요 간 식용 으로 구매 해서 불 필요 한 플라스틱 케이스 없다 어...</td>\n",
       "      <td>포장/Noun 자다/Verb 되다/Verb 어요/Noun 간/Noun 식용/Noun...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>48389</td>\n",
       "      <td>제품포장</td>\n",
       "      <td>녹다</td>\n",
       "      <td>물에잘녹고 아기가잘먹어요\\n덕분에 폭풍성장중입니다~^^</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rkgb***</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>6510886109</td>\n",
       "      <td>앱솔루트 센서티브 2단계(100일~6개월) 900g 3캔</td>\n",
       "      <td>분유 앱솔루트 [ 센서티브 ] [ 2단계 ] [ 900g ]</td>\n",
       "      <td>물 에 자다 녹다 아기 가 잘 먹다 어요 덕분 폭풍성 장 중 이다</td>\n",
       "      <td>물/Noun 에/Josa 자다/Verb 녹다/Verb 아기/Noun 가/Josa 잘...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 GROUP2 KEYWORD                                      리뷰상세내용  \\\n",
       "353       38440   제품포장      포장  포장 잘 되있어요\\n간식용으로 구매해서 불필요한 플라스틱케이스 없어서 좋아요   \n",
       "422       48389   제품포장      녹다              물에잘녹고 아기가잘먹어요\\n덕분에 폭풍성장중입니다~^^   \n",
       "\n",
       "     구매자평점                                              포토/영상      등록자  \\\n",
       "353      5  https://phinf.pstatic.net/checkout.phinf/20230...  ssk9***   \n",
       "422      5                                                NaN  rkgb***   \n",
       "\n",
       "        리뷰등록일1        상품번호                                      상품명  \\\n",
       "353 2023-03-23  4697498993  페레로 로쉐 T3 3개입 16세트 (총 48개입) (쇼핑백 없는 구성)   \n",
       "422 2023-03-24  6510886109          앱솔루트 센서티브 2단계(100일~6개월) 900g 3캔   \n",
       "\n",
       "                            product_nm  \\\n",
       "353                  페레로 [ 로쉐 ] [ t3 ]   \n",
       "422  분유 앱솔루트 [ 센서티브 ] [ 2단계 ] [ 900g ]   \n",
       "\n",
       "                                                 token  \\\n",
       "353  포장 자다 되다 어요 간 식용 으로 구매 해서 불 필요 한 플라스틱 케이스 없다 어...   \n",
       "422              물 에 자다 녹다 아기 가 잘 먹다 어요 덕분 폭풍성 장 중 이다    \n",
       "\n",
       "                                    token_attribution2  lenght  KeyBERT  \n",
       "353  포장/Noun 자다/Verb 되다/Verb 어요/Noun 간/Noun 식용/Noun...      17        1  \n",
       "422  물/Noun 에/Josa 자다/Verb 녹다/Verb 아기/Noun 가/Josa 잘...      15        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['KeyBERT'] == 1].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc74cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
