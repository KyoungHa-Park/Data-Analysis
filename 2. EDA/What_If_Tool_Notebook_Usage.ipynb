{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiNxsd4_q9wq"
   },
   "source": [
    "### What-If Tool in colab and jupyter notebooks\n",
    "\n",
    "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) inside of a colab or jupyter notebook.\n",
    "\n",
    "If running in colab, you can use this notebook out-of-the-box.\n",
    "\n",
    "If running in jupyter, you must run the What-If Tool [widget installation instructions](https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/interactive_inference#how-do-i-use-it-in-a-jupyter-notebook) before using this notebook.\n",
    "\n",
    "This notebook trains a linear classifier on the [UCI census problem](https://archive.ics.uci.edu/ml/datasets/census+income) (predicting whether a person earns more than $50K from their census information).\n",
    "\n",
    "It then visualizes the results of the trained classifier on test data using the What-If Tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the What-If Tool widget if running in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqB2tjOMETmr"
   },
   "outputs": [],
   "source": [
    "#@title Install the What-If Tool widget if running in Colab {display-mode: \"form\"}\n",
    "\n",
    "# If running in Colab then pip install, otherwise no need.\n",
    "try:\n",
    "  import google.colab\n",
    "  !pip install --upgrade witwidget\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlwjF-Nnmoww"
   },
   "outputs": [],
   "source": [
    "#@title Define helper functions {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec\n",
    "\n",
    "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# list of columns from that spec to use.\n",
    "#\n",
    "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "def create_feature_columns(columns, feature_spec):\n",
    "    ret = []\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
    "            ret.append(tf.feature_column.numeric_column(col))\n",
    "        else:\n",
    "            ret.append(tf.feature_column.indicator_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n",
    "    return ret\n",
    "\n",
    "# An input function for providing input to a model from tf.Examples\n",
    "def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
    "                       num_epochs=None, \n",
    "                       batch_size=64):\n",
    "    def ex_generator():\n",
    "        for i in range(len(examples)):\n",
    "            yield examples[i].SerializeToString()\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    return dataset\n",
    "\n",
    "# Parses Tf.Example protos into features for the input function.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training dataset from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nu398ARdeuxe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital-Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-Gain</th>\n",
       "      <th>Capital-Loss</th>\n",
       "      <th>Hours-per-week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Over-50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age     Workclass  fnlwgt Education  Education-Num      Marital-Status  \\\n",
       "32559   22       Private  201490   HS-grad              9       Never-married   \n",
       "32560   52  Self-emp-inc  287927   HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "            Occupation Relationship   Race     Sex  Capital-Gain  \\\n",
       "32559     Adm-clerical    Own-child  White    Male             0   \n",
       "32560  Exec-managerial         Wife  White  Female         15024   \n",
       "\n",
       "       Capital-Loss  Hours-per-week        Country Over-50K  \n",
       "32559             0              20  United-States    <=50K  \n",
       "32560             0              40  United-States     >50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Read training dataset from CSV {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the CSV containing the dataset to train on.\n",
    "csv_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "\n",
    "# Set the column names for the columns in the CSV. If the CSV's first line is a header line containing\n",
    "# the column names, then set this to None.\n",
    "csv_columns = [\n",
    "  \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital-Status\",\n",
    "  \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-Gain\", \"Capital-Loss\",\n",
    "  \"Hours-per-week\", \"Country\", \"Over-50K\"]\n",
    "\n",
    "# Read the dataset from the provided CSV and print out information about it.\n",
    "df = pd.read_csv(csv_path, names=csv_columns, skipinitialspace=True)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify input columns and column to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67DYIFxoevt2"
   },
   "outputs": [],
   "source": [
    "#@title Specify input columns and column to predict {display-mode: \"form\"}\n",
    "import numpy as np\n",
    "\n",
    "# Set the column in the dataset you wish for the model to predict\n",
    "label_column = 'Over-50K'\n",
    "\n",
    "# Make the label column numeric (0 and 1), for use in our model.\n",
    "# In this case, examples with a target value of '>50K' are considered to be in\n",
    "# the '1' (positive) class and all other examples are considered to be in the\n",
    "# '0' (negative) class.\n",
    "make_label_column_numeric(df, label_column, lambda val: val == '>50K')\n",
    "\n",
    "# Set list of all columns from the dataset we will use for model input.\n",
    "input_features = [\n",
    "  'Age', 'Workclass', 'Education', 'Marital-Status', 'Occupation',\n",
    "  'Relationship', 'Race', 'Sex', 'Capital-Gain', 'Capital-Loss',\n",
    "  'Hours-per-week', 'Country']\n",
    "\n",
    "# Create a list containing all input features and the label column\n",
    "features_and_labels = input_features + [label_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset to tf.Example protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BV4f_4_Lex22"
   },
   "outputs": [],
   "source": [
    "#@title Convert dataset to tf.Example protos {display-mode: \"form\"}\n",
    "\n",
    "examples = df_to_examples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyLr-_0de1Ii"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\455709305.py:31: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\455709305.py:34: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\455709305.py:33: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\2580030583.py:10: LinearClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.linear) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\head_utils.py:54: BinaryClassHead.__init__ (from tensorflow_estimator.python.estimator.head.binary_class_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:944: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1842: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\khpark\\AppData\\Local\\Temp\\tmptwktoflr\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\khpark\\\\AppData\\\\Local\\\\Temp\\\\tmptwktoflr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\455709305.py:44: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\455709305.py:44: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\ftrl.py:173: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1414: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1417: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1454: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\khpark\\AppData\\Local\\Temp\\tmptwktoflr\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'head/losses/Cast' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\2580030583.py\", line 12, in <module>\n      classifier.train(train_inpf, steps=num_steps)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n      loss = self._train_model(input_fn, hooks, saving_listeners)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n      return self._train_model_default(input_fn, hooks, saving_listeners)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1214, in _train_model_default\n      estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1174, in _call_model_fn\n      model_fn_results = self._model_fn(features=features, **kwargs)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 934, in _model_fn\n      return _linear_model_fn_v2(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 677, in _linear_model_fn_v2\n      return head.create_estimator_spec(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py\", line 278, in create_estimator_spec\n      self._create_tpu_estimator_spec(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 565, in _create_tpu_estimator_spec\n      regularized_training_loss = self.loss(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 285, in loss\n      labels = self._processed_labels(logits, labels)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 255, in _processed_labels\n      labels = tf.cast(labels, dtype=tf.dtypes.float32)\nNode: 'head/losses/Cast'\nCast string to float is not supported\n\t [[{{node head/losses/Cast}}]]\n\nOriginal stack trace for 'head/losses/Cast':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n    self._run_once()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n    handle._run()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\2580030583.py\", line 12, in <module>\n    classifier.train(train_inpf, steps=num_steps)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1214, in _train_model_default\n    estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1174, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 934, in _model_fn\n    return _linear_model_fn_v2(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 677, in _linear_model_fn_v2\n    return head.create_estimator_spec(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py\", line 278, in create_estimator_spec\n    self._create_tpu_estimator_spec(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 565, in _create_tpu_estimator_spec\n    regularized_training_loss = self.loss(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 285, in loss\n    labels = self._processed_labels(logits, labels)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 255, in _processed_labels\n    labels = tf.cast(labels, dtype=tf.dtypes.float32)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1018, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2233, in cast\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Cast string to float is not supported\n\t [[{{node head/losses/Cast}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m train_inpf \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(tfexamples_input_fn, examples, feature_spec, label_column)\n\u001b[0;32m     10\u001b[0m classifier \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mLinearClassifier(\n\u001b[0;32m     11\u001b[0m     feature_columns\u001b[39m=\u001b[39mcreate_feature_columns(input_features, feature_spec))\n\u001b[1;32m---> 12\u001b[0m classifier\u001b[39m.\u001b[39;49mtrain(train_inpf, steps\u001b[39m=\u001b[39;49mnum_steps)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[0;32m    361\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1217\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1214\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39mTRAIN,\n\u001b[0;32m   1215\u001b[0m                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig)\n\u001b[0;32m   1216\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1218\u001b[0m                                        hooks, global_step_tensor,\n\u001b[0;32m   1219\u001b[0m                                        saving_listeners)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1533\u001b[0m, in \u001b[0;36mEstimator._train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1530\u001b[0m   \u001b[39m# just as keras(https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/engine/training.py#L1093),\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m   \u001b[39m# trace should be enabled for every step\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m   \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mcurrent_step, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m-> 1533\u001b[0m     _, loss \u001b[39m=\u001b[39m mon_sess\u001b[39m.\u001b[39;49mrun([estimator_spec\u001b[39m.\u001b[39;49mtrain_op, estimator_spec\u001b[39m.\u001b[39;49mloss])\n\u001b[0;32m   1534\u001b[0m \u001b[39mif\u001b[39;00m current_step \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1535\u001b[0m   tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mTraining with estimator made no steps. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1536\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mPerhaps input is empty or misspecified.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:778\u001b[0m, in \u001b[0;36m_MonitoredSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, fetches, feed_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, run_metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    765\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Run ops in the monitored session.\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \n\u001b[0;32m    767\u001b[0m \u001b[39m  This method is completely compatible with the `tf.Session.run()` method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39m    Same as `tf.Session.run()`.\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    779\u001b[0m       fetches,\n\u001b[0;32m    780\u001b[0m       feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[0;32m    781\u001b[0m       options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    782\u001b[0m       run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1307\u001b[0m, in \u001b[0;36m_RecoverableSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess:\n\u001b[0;32m   1306\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_session()\n\u001b[1;32m-> 1307\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m   1308\u001b[0m       fetches,\n\u001b[0;32m   1309\u001b[0m       feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[0;32m   1310\u001b[0m       options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1311\u001b[0m       run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n\u001b[0;32m   1312\u001b[0m \u001b[39mexcept\u001b[39;00m _PREEMPTION_ERRORS \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1313\u001b[0m   logging\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1314\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mAn error was raised. This may be due to a preemption in \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1315\u001b[0m       \u001b[39m'\u001b[39m\u001b[39ma connected worker or parameter server. The current \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mincreasing the number of parameter servers assigned to \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1321\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthe job. Error: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, e)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1397\u001b[0m, in \u001b[0;36m_CoordinatedSession.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1396\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1397\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1398\u001b[0m   \u001b[39mexcept\u001b[39;00m _PREEMPTION_ERRORS:\n\u001b[0;32m   1399\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1464\u001b[0m, in \u001b[0;36m_HookedSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[39m# Do session run.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m run_metadata \u001b[39m=\u001b[39m run_metadata \u001b[39mor\u001b[39;00m config_pb2\u001b[39m.\u001b[39mRunMetadata()\n\u001b[1;32m-> 1464\u001b[0m outputs \u001b[39m=\u001b[39m _WrappedSession\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m   1465\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1466\u001b[0m     fetches\u001b[39m=\u001b[39;49mactual_fetches,\n\u001b[0;32m   1467\u001b[0m     feed_dict\u001b[39m=\u001b[39;49mfeed_dict,\n\u001b[0;32m   1468\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1469\u001b[0m     run_metadata\u001b[39m=\u001b[39;49mrun_metadata)\n\u001b[0;32m   1471\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hooks:\n\u001b[0;32m   1472\u001b[0m   hook\u001b[39m.\u001b[39mafter_run(\n\u001b[0;32m   1473\u001b[0m       run_context,\n\u001b[0;32m   1474\u001b[0m       session_run_hook\u001b[39m.\u001b[39mSessionRunValues(\n\u001b[0;32m   1475\u001b[0m           results\u001b[39m=\u001b[39moutputs[hook] \u001b[39mif\u001b[39;00m hook \u001b[39min\u001b[39;00m outputs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1476\u001b[0m           options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   1477\u001b[0m           run_metadata\u001b[39m=\u001b[39mrun_metadata))\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1228\u001b[0m, in \u001b[0;36m_WrappedSession.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 1228\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[0;32m   1393\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'head/losses/Cast' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\2580030583.py\", line 12, in <module>\n      classifier.train(train_inpf, steps=num_steps)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n      loss = self._train_model(input_fn, hooks, saving_listeners)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n      return self._train_model_default(input_fn, hooks, saving_listeners)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1214, in _train_model_default\n      estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1174, in _call_model_fn\n      model_fn_results = self._model_fn(features=features, **kwargs)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 934, in _model_fn\n      return _linear_model_fn_v2(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 677, in _linear_model_fn_v2\n      return head.create_estimator_spec(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py\", line 278, in create_estimator_spec\n      self._create_tpu_estimator_spec(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 565, in _create_tpu_estimator_spec\n      regularized_training_loss = self.loss(\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 285, in loss\n      labels = self._processed_labels(logits, labels)\n    File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 255, in _processed_labels\n      labels = tf.cast(labels, dtype=tf.dtypes.float32)\nNode: 'head/losses/Cast'\nCast string to float is not supported\n\t [[{{node head/losses/Cast}}]]\n\nOriginal stack trace for 'head/losses/Cast':\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n    self._run_once()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n    handle._run()\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n    result = runner(coro)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"C:\\Users\\khpark\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\khpark\\AppData\\Local\\Temp\\ipykernel_16468\\2580030583.py\", line 12, in <module>\n    classifier.train(train_inpf, steps=num_steps)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 360, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1186, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1214, in _train_model_default\n    estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1174, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 934, in _model_fn\n    return _linear_model_fn_v2(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py\", line 677, in _linear_model_fn_v2\n    return head.create_estimator_spec(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\base_head.py\", line 278, in create_estimator_spec\n    self._create_tpu_estimator_spec(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 565, in _create_tpu_estimator_spec\n    regularized_training_loss = self.loss(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 285, in loss\n    labels = self._processed_labels(logits, labels)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py\", line 255, in _processed_labels\n    labels = tf.cast(labels, dtype=tf.dtypes.float32)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1018, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2233, in cast\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\khpark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "#@title Create and train the classifier {display-mode: \"form\"}\n",
    "\n",
    "num_steps = 5000  #@param {type: \"number\"}\n",
    "\n",
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df, features_and_labels)\n",
    "\n",
    "# Define and train the classifier\n",
    "train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=create_feature_columns(input_features, feature_spec))\n",
    "classifier.train(train_inpf, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUQVro76e38Q"
   },
   "outputs": [],
   "source": [
    "#@title Invoke What-If Tool for test data and the trained model {display-mode: \"form\"}\n",
    "\n",
    "num_datapoints = 2000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget\n",
    "\n",
    "# Load up the test dataset\n",
    "test_csv_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "test_df = pd.read_csv(test_csv_path, names=csv_columns, skipinitialspace=True,\n",
    "  skiprows=1)\n",
    "make_label_column_numeric(test_df, label_column, lambda val: val == '>50K.')\n",
    "test_examples = df_to_examples(test_df[0:num_datapoints])\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(test_examples).set_estimator_and_feature_spec(\n",
    "    classifier, feature_spec).set_label_vocab(['Under 50K', 'Over 50K'])\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "What-If Tool Notebook Usage",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
